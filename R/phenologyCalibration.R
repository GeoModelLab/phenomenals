#' Run phenologyCalibration
#'
#' This function runs the Phenomenals phenology model by passing weather data and phenological observations (BBCH) directly from R to the underlying C# executable.
#' Users do not need to manage configuration files or binaries manually. All paths and execution logic are handled internally, and only core calibration settings are exposed.
#'
#' @param weather_data A data frame containing hourly weather data. Must include the following columns: `Latitude`, `Longitude`, `DateTime` (as POSIXct or character), `Temperature` (¬∞C), `Precipitation` (mm), `RelativeHumidity` (%), `Radiation` (MJ/m¬≤), and `WindSpeed` (m/s).
#' @param referenceBBCH A data frame containing BBCH phenological observations. Must include: `Variety`, `Site`, `Latitude`, `Longitude`, `Date`, `BBCH`
#' @param phenomenalsParameters A nested list of model parameters (usually loaded from `phenomenals::phenomenalsParameters`), structured as `list[species][[class]][[parameter]]`, where each parameter is a list with:
#'   - `min`: Minimum calibration value (numeric)
#'   - `max`: Maximum calibration value (numeric)
#'   - `value`: Default value used in simulation (numeric)
#'   - `calibration`: Logical; `TRUE` if the parameter is subject to calibration
#'
#'   You can start with `phenomenals::phenomenalsParameters` and modify it as needed. This list will be automatically converted to the CSV format required by the C# executable.
#' @param start_year The first year of the simulation or calibration period (default is 2000).
#' @param end_year The last year of the simulation or calibration period (default is 2025).
#' @param sites A character vector of site names (e.g., `"ColliOrientali"`). Defaults to `"site1"` if not provided.
#' @param varieties A character vector of variety names to include in the calibration (default: `"all"`).
#' @param iterations Number of iterations for each simplex (default: 100).
#' @param timestep Time step of the input weather data; must be `"hourly"` (default) or `"daily"`.
#'
#' @return A named list of data frames containing model outputs, loaded from the output CSV files generated by the Phenomenals executable. The names of the list entries correspond to the output file names (without `.csv`).
#'
#' @examples
#' \dontrun{
#' result <- phenologyCalibration(
#'   weather_data = colliOrientali,
#'   referenceBBCH = bbchSample,
#'   phenomenalsParameters,
#'   start_year = 2010,
#'   end_year = 2020,
#'   sites = "ColliOrientali",
#'   varieties = "Merlot",
#'   iterations = 300,
#'   timestep = 'daily'
#' )
#' head(result$phenology)
#' }
#' @export
phenologyCalibration <- function(weather_data,
                                 referenceBBCH,
                           phenomenalsParameters,
                           start_year = 2000,
                           end_year = 2025,
                           sites = "all",
                           varieties = "all",
                           iterations = 100,
                           timestep = "daily") {
  # === VALIDATION ===

  # Check weather_data
  if (!is.data.frame(weather_data)) stop("‚ùå 'weather_data' must be a data frame.")
  if (!"Site" %in% names(weather_data)) stop("‚ùå 'weather_data' must contain a 'Site' column.")

  # Check referenceBBCH
  if (!is.data.frame(referenceBBCH)) stop("‚ùå 'referenceBBCH' must be a data frame.")
  if (!"Site" %in% names(referenceBBCH)) stop("‚ùå 'referenceBBCH' must contain a 'Site' column.")
  if (!"Variety" %in% names(referenceBBCH)) stop("‚ùå 'referenceBBCH' must contain a 'Variety' column.")

  # Check phenomenalsParameters
  if (!is.list(phenomenalsParameters)) stop("‚ùå 'phenomenalsParameters' must be a nested list.")

  # Check years
  if (!is.numeric(start_year) || length(start_year) != 1) stop("‚ùå 'start_year' must be a single numeric value.")
  if (!is.numeric(end_year) || length(end_year) != 1) stop("‚ùå 'end_year' must be a single numeric value.")
  if (start_year > end_year) stop("‚ùå 'start_year' must be less than or equal to 'end_year'.")

  # Check sites
  if (!(is.character(sites) || is.null(sites))) stop("‚ùå 'sites' must be a character vector or 'all'.")

  # Check varieties
  if (!(is.character(varieties) || is.null(varieties))) stop("‚ùå 'varieties' must be a character vector or 'all'.")

  # Check iterations
  if (!is.numeric(iterations) || length(iterations) != 1 || iterations <= 0) {
    stop("‚ùå 'iterations' must be a single positive number.")
  }

  # Check timestep
  if (!timestep %in% c("daily", "hourly")) {
    stop("‚ùå 'timestep' must be either 'daily' or 'hourly'.")
  }

  # CONFIGURATION----
    # Path to the EXE
  pkg_path <- system.file("", package = "phenomenals")
    exe_path <- system.file("bin", "phenomenals.exe", package = "phenomenals")
    if (!file.exists(exe_path)) stop("‚ùå Executable not found.")

    # Path to fixed runtime directory inside the package
    work_dir <- normalizePath("inst/bin", mustWork = FALSE)
    #if (dir.exists(work_dir)) unlink(work_dir, recursive = TRUE)
   # dir.create(work_dir, recursive = TRUE)

    # Subfolders
    input_weather_dir <- file.path(dirname(exe_path), "inputFiles", "weather", tolower(timestep))
    input_ref_dir     <- file.path(dirname(exe_path), "inputFiles", "referenceData")
    input_plant_dir   <- file.path(dirname(exe_path), "inputFiles", "plant")

    dir.create(input_weather_dir, recursive = TRUE, showWarnings = FALSE)
    dir.create(input_ref_dir, recursive = TRUE, showWarnings = FALSE)
    dir.create(input_plant_dir, recursive = TRUE, showWarnings = FALSE)

    # WRITE WEATHER FILE ----
    # Handle 'all' sites logic
    # Validate required columns
    if (!"Site" %in% names(weather_data)) stop("Missing 'Site' column in weather_data")
    if (!"Site" %in% names(referenceBBCH)) stop("Missing 'Site' column in referenceBBCH")

    # Determine the list of sites to use
    if (identical(sites, "all")) {
      sites <- intersect(unique(weather_data$Site), unique(referenceBBCH$Site))
      if (length(sites) == 0) stop("‚ùå No overlapping sites between weather_data and referenceBBCH")
    }

    site_names <- sites  # This will be used in the JSON config

    # WRITE REFERENCE DATA ====
    filtered_ref <- referenceBBCH
    if (!is.null(sites)) {
      filtered_ref <- filtered_ref[filtered_ref$Site %in% sites, ]
    }
    if (!identical(varieties, "all")) {
      filtered_ref <- filtered_ref[filtered_ref$Variety %in% varieties, ]
    }

    # Filtered reference data
    filtered_ref <- referenceBBCH
    if (!is.null(sites)) {
      filtered_ref <- filtered_ref[filtered_ref$Site %in% sites, ]
    }
    if (!identical(varieties, "all")) {
      filtered_ref <- filtered_ref[filtered_ref$Variety %in% varieties, ]
    }

    # Check if all required combinations exist
    required_combos <- expand.grid(Site = sites, Variety = if (identical(varieties, "all")) unique(referenceBBCH$Variety) else varieties, stringsAsFactors = FALSE)

    missing_combos <- required_combos[!paste(required_combos$Site, required_combos$Variety) %in%
                                        paste(filtered_ref$Site, filtered_ref$Variety), ]

    if (nrow(missing_combos) > 0) {
      stop(
        paste0(
          "‚ùå Missing experiments in referenceBBCH for the following site-variety combinations:\n",
          paste(apply(missing_combos, 1, function(row) paste0("  - Site: ", row["Site"], ", Variety: ", row["Variety"])), collapse = "\n")
        )
      )
    }


    ref_file <- file.path(input_ref_dir, "referenceBBCH.csv")
    write.table(filtered_ref, ref_file, sep = ",", row.names = FALSE, col.names = TRUE, quote = FALSE)

    # WRITE PARAMETERS FILE----
    params_to_df <- function(nested_list) {
      rows <- lapply(names(nested_list), function(species) {
        lapply(names(nested_list[[species]]), function(class) {
          lapply(names(nested_list[[species]][[class]]), function(par) {
            row <- nested_list[[species]][[class]][[par]]
            data.frame(
              species = species,
              class = class,
              parameter = par,
              min = row$min,
              max = row$max,
              value = row$value,
              calibration = ifelse(row$calibration, "x", ""),
              stringsAsFactors = FALSE
            )
          })
        })
      })
      flat_list <- do.call(c, do.call(c, rows))
      do.call(rbind, flat_list)
    }

    params_df <- params_to_df(phenomenalsParameters)
    param_file <- file.path(input_plant_dir, "phenologyParameters.csv")
    write.table(params_df, file = param_file, sep = ",", row.names = FALSE, col.names = TRUE, quote = FALSE)

    # === WRITE WEATHER FILES PER SITE ===
    for (s in site_names) {
      site_weather <- weather_data[weather_data$Site == s, ]

      # Identify and rename date column
      date_col <- names(weather_data)[tolower(names(weather_data)) %in% c("datetime", "date")]
      if (length(date_col) == 0) stop("‚ùå 'weather_data' must contain a 'DateTime' or 'Date' column.")

      names(weather_data)[names(weather_data) == date_col] <- "date"

      # Ensure character type before parsing
      if (!is.character(weather_data$DateTime)) {
        weather_data$date <- as.character(weather_data$date)
      }

      # Try parsing with the known format
      weather_data$date <- suppressWarnings(as.Date(weather_data$date, format = "%m/%d/%Y"))

      # Check if any failed
      if (anyNA(weather_data$date)) {
        stop("‚ùå Some 'date' entries in weather_data could not be parsed with format '%m/%d/%Y'. Check for typos or inconsistencies.")
      }

      # Write weather CSV for site
      weather_file <- file.path(input_weather_dir, paste0(s, ".csv"))
      write.table(site_weather, file = weather_file, sep = ",", row.names = FALSE, col.names = TRUE, quote = FALSE)
      message(glue::glue("üå¶Ô∏è  Weather data written for site '{s}' ‚ûú {basename(weather_file)}"))
    }


    # BUILD JSON ----
    config <- list(
      settings = list(
        startYear = start_year,
        endYear = end_year,
        sites = as.list(site_names),
        isCalibration = "true",#tolower(as.character(is_calibration)),
        varieties = as.list(varieties),
        simplexes = 1,
        iterations = iterations,
        weatherTimeStep = tolower(timestep)
      ),
      paths = list(
        weatherDir = normalizePath(dirname(input_weather_dir), winslash = "\\", mustWork = FALSE),
        referenceFileBBCH = normalizePath(ref_file, winslash = "\\", mustWork = FALSE),
        plantParamFile = normalizePath(param_file, winslash = "\\", mustWork = FALSE)
      )
    )

    config_path <- file.path(dirname(exe_path), "phenomenalsConfig.json")
    jsonlite::write_json(config, config_path, auto_unbox = TRUE, pretty = TRUE)

    cmd <- paste(shQuote(exe_path), shQuote(config_path))
    cat("üê¢ Initiating phenology calibration...\n‚åõ Be cool ‚Äî algorithms are thinking really hard right now.\nüç∑ Good wine takes time, and so does this model!\n")
    flush.console()

    output <- tryCatch({
      system(cmd, intern = TRUE, ignore.stderr = FALSE)
    }, error = function(e) {
      stop("‚ùå C# model execution failed: ", e$message)
    })

    # Show output for debugging
    cat(paste(output, collapse = "\n"), "\n")

    # Check for failure message
    if (any(grepl("no experiment available", tolower(output)))) {
      stop("‚ùå Calibration failed: No experiment available for at least one variety-site combination.")
    }

    cat("‚úÖ Calibration completed successfully\n")
    flush.console()

  #READ OUTPUT FILES----
  #output files
  list_files_params <- list.files(paste0(dirname(exe_path),"\\calibratedVarieties"),
                                  pattern = "\\.csv$", full.names = TRUE)
  # Combine results into a single data frame
    df_params <- do.call(rbind, lapply(list_files_params, function(file) {
      dt <- data.table::fread(file)
      dt$file_name <- tolower(gsub("\\.csv$", "", basename(file)))  # "CabernetS.csv" -> "cabernets"
      dt$file_name <- sub("s$", "", dt$file_name)                   # remove trailing 's' to get "cabernet"
      return(dt)
    })) |>
      tidyr::separate(param, into = c("param_type", "parameter"), sep = "_", remove = FALSE) |>
      tidyr::separate(file_name, into = c("filetype", "site", "variety"), sep = "_", remove = FALSE) |>
      dplyr::select(-c(param, param_type, file_name, filetype))

    # 2. Extract min/max from nested structure
    flatten_param_limits <- function(nested_list) {
      rows <- list()

      for (species in names(nested_list)) {
        for (class in names(nested_list[[species]])) {
          for (parameter in names(nested_list[[species]][[class]])) {
            param_info <- nested_list[[species]][[class]][[parameter]]
            rows[[length(rows) + 1]] <- data.frame(
              parameter = parameter,
              class = class,
              species = species,
              min = as.numeric(param_info$min),
              max = as.numeric(param_info$max),
              stringsAsFactors = FALSE
            )
          }
        }
      }

      do.call(rbind, rows)
    }

    #load parameter limits
    param_limits <- flatten_param_limits(phenomenalsParameters)

    #OBJECT TO RETURN!
    df_params_all <- df_params |>
      (\(x) suppressMessages(dplyr::left_join(x, param_limits)))() |>
      dplyr::select(site, variety, parameter, value, min, max)

    #OUTPUTS----
    list_files_out <- list.files(paste0(dirname(exe_path),"\\outputsCalibration_BBCH"),
                                    pattern = "\\.csv$", full.names = TRUE)

    #OBJECT TO RETURN!
    # Read and bind all files with filename as a column
    df_sim <- do.call(rbind, lapply(list_files_out, function(file) {
      df <- data.table::fread(file)
      # Extract region name from filename
      file_name <- basename(file)
      region <- sub(".*_(.*?)\\.csv", "\\1", file_name)
      df$region <- region
      return(df)
    })) |>
      dplyr::select(-region)

    temporary_files_to_delete <- list_files_out

    # Cleanup any temporary files created during averaging
    if (length(temporary_files_to_delete) > 0) {
      message("üßπ Cleaning up temporary output files...")
      file.remove(temporary_files_to_delete)
      message(paste0("üóëÔ∏è Deleted ", length(temporary_files_to_delete), " temporary output files."))
    }

    #objects returned by the function
    return(list(parameters = df_params_all,
                phenology = as.data.frame(df_sim)))
}


